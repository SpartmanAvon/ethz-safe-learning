{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Spread Toy Example\n",
    "## Initilization Anchored NN Ensemble Sanity Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I want to demonstrate that my tensorflow implementation of the ensemble neural network is actually working and useful. In the spirit of times, I will try to learn the _hypothetical_ spreading of the COVID-19 disease in the _hypothetical_ island of Wakanda through the period of one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from simba.infrastructure import MLPEnsemble\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate some data using the [SIR model](https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html) of covid19: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_covid_19_infection_rate_data():\n",
    "    # https://www.lewuathe.com/covid-19-dynamics-with-sir-model.html\n",
    "    # https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/\n",
    "    population = 15000\n",
    "    days = 365\n",
    "    i_0, r_0 = 2, 0\n",
    "    s_0 = population - i_0 - r_0\n",
    "    beta, gamma = 0.3, 0.02\n",
    "    t = np.linspace(0, days, days)\n",
    "\n",
    "    def deriv(y, t, population, beta, gamma):\n",
    "        S, I, R = y\n",
    "        dSdt = -beta * S * I / population\n",
    "        dIdt = beta * S * I / population - gamma * I\n",
    "        dRdt = gamma * I\n",
    "        return dSdt, dIdt, dRdt\n",
    "    y_0 = s_0, i_0, r_0\n",
    "    ret = odeint(deriv, y_0, t, args=(population, beta, gamma))\n",
    "    _, infected_people, _ = ret.transpose()\n",
    "    return t, infected_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have only have access to noisy measurements of how many people were sick on a certain day: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, infected_people = generate_covid_19_infection_rate_data()\n",
    "n_samples = 2\n",
    "noise = 0.1\n",
    "inputs = np.array([])\n",
    "targets = np.array([])\n",
    "for day, sick_people_that_day in zip(time, infected_people):\n",
    "    inputs = np.append(inputs, np.full(n_samples, day))\n",
    "    targets = np.append(targets, np.random.normal(\n",
    "    sick_people_that_day, noise * sick_people_that_day, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "def make_model(sess):\n",
    "    mlp_dict = dict(\n",
    "        input_dim=1,\n",
    "        targets_dim=1,\n",
    "        learning_rate=0.01,\n",
    "        n_layers=3,\n",
    "        hidden_size=128,\n",
    "        activation=tf.nn.relu,\n",
    "        anchor=False,\n",
    "        init_std_bias=0.5,\n",
    "        init_std_weights=0.5,\n",
    "        data_noise=0.5\n",
    "    )\n",
    "    return MLPEnsemble(\n",
    "        sess=sess,\n",
    "        ensemble_size=5,\n",
    "        n_epochs=4000,\n",
    "        batch_size=512,\n",
    "        **mlp_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yardenas/ethz/semester_project/ethz-safe-learning/simba/infrastructure/ensembled_anchored_nn.py:56: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/yardenas/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "Epoch  0  | Losses = [216438.68977813932, 247910.72325751593, 240608.1325727085, 223406.16587615234, 244755.86627295462]\n",
      "Epoch  20  | Losses = [95283.43399483076, 215017.64836877983, 88428.76510919986, 107969.99611274821, 89255.34101078685]\n",
      "Epoch  40  | Losses = [87205.29129651809, 142031.46124455694, 89907.35753266234, 84035.60742481922, 83597.9734372082]\n",
      "Epoch  60  | Losses = [71895.46821505246, 97233.23930277654, 82065.80097302527, 76709.30095421463, 78842.9152918474]\n",
      "Epoch  80  | Losses = [33813.45662768794, 95287.45924649393, 50411.874681218695, 55658.039614181434, 79247.65018348832]\n",
      "Epoch  100  | Losses = [8667.044589958829, 77805.65736219754, 12823.70629089434, 15222.592433199057, 37881.90483607827]\n",
      "Epoch  120  | Losses = [5903.756404832841, 67686.04967927824, 4532.431597558038, 9337.426473463405, 11428.371570980396]\n",
      "Epoch  140  | Losses = [3725.2599023500597, 63450.4032093791, 3387.2982165103713, 9011.770896376831, 5543.8055994571405]\n",
      "Epoch  160  | Losses = [3004.177454584596, 44704.06579611402, 3271.6253927714356, 7294.129401567402, 5445.71608549814]\n",
      "Epoch  180  | Losses = [3697.911780552644, 34761.669682141815, 3255.4934374756162, 6666.904343645626, 4862.112599951129]\n",
      "Epoch  200  | Losses = [3221.2588055064284, 30930.517275608596, 2746.550684493892, 7197.456073887506, 3923.3547011321625]\n",
      "Epoch  220  | Losses = [2939.2438310947077, 24468.635305971682, 2489.6514245906806, 5362.323194322856, 3433.6254650638757]\n",
      "Epoch  240  | Losses = [2778.5570097883287, 17557.369808312527, 2215.7555996788146, 5611.387356176462, 4177.925235275339]\n",
      "Epoch  260  | Losses = [2096.897757255569, 16654.95897997518, 2719.2001591866047, 4166.152366103537, 3291.7745042331235]\n",
      "Epoch  280  | Losses = [2905.8199104390574, 14276.836412537765, 2188.975621226347, 3632.9439160750294, 2863.0533484971656]\n",
      "Epoch  300  | Losses = [2017.6867018406624, 10585.476954520509, 2238.3770230633527, 3078.8807920924305, 3294.204012612136]\n",
      "Epoch  320  | Losses = [1961.6264187442696, 9547.163041064898, 2613.2782263231065, 2757.9644303393393, 3385.665181982162]\n",
      "Epoch  340  | Losses = [3321.0620988762107, 10159.911870731325, 2797.002143439218, 3166.5363062933284, 2932.906204557596]\n",
      "Epoch  360  | Losses = [2338.3491650781484, 9406.12348472522, 2487.4817092938747, 2382.7481871462483, 2929.8659360363986]\n",
      "Epoch  380  | Losses = [2081.8698382947673, 8986.218399121539, 2627.9958905814533, 3001.8388223230436, 2849.5356663959806]\n",
      "Epoch  400  | Losses = [2945.652532021781, 7192.816218189784, 2376.2367944268285, 2737.750288093804, 2843.736389104053]\n",
      "Epoch  420  | Losses = [2892.765717448777, 6987.4956221287985, 2217.870890762604, 2644.7554609934236, 3053.0388179478828]\n",
      "Epoch  440  | Losses = [4417.466971685881, 7577.821751431655, 2566.546121293468, 2436.7626177924153, 2486.9829655000026]\n",
      "Epoch  460  | Losses = [1923.8620472635127, 7241.345867531597, 2522.9410225206216, 2523.964395402931, 2515.1556692205277]\n",
      "Epoch  480  | Losses = [2877.8153085685894, 6159.899135047366, 2494.1350970935873, 2765.186951360949, 2406.631036441589]\n",
      "Epoch  500  | Losses = [1990.1615938269106, 6668.3844484006, 2293.666821480271, 2602.7247411121166, 2348.805045600085]\n",
      "Epoch  520  | Losses = [2748.460810728282, 5783.94414414194, 2152.4208644473742, 2661.0832397931736, 2332.6009304366225]\n",
      "Epoch  540  | Losses = [2822.4512967445853, 6088.544059828609, 2603.137540332039, 2368.2637669181463, 2687.7406368237225]\n",
      "Epoch  560  | Losses = [2786.5932922705492, 5830.122907341334, 2638.8839644534487, 2289.6541355262393, 2713.2145366455657]\n",
      "Epoch  580  | Losses = [1916.2437266802078, 5043.434215079588, 2609.0239335105907, 2653.7248921090863, 2689.7880320667878]\n",
      "Epoch  600  | Losses = [2679.1623665282236, 4825.879775201387, 2196.574000502293, 2676.6778454344826, 2334.9538450399814]\n"
     ]
    }
   ],
   "source": [
    "mean, std = inputs.mean(), inputs.std()\n",
    "n_particles = 20\n",
    "x_val = np.tile(time, n_particles)\n",
    "x = (inputs - mean) / (std + 1e-8)\n",
    "with tf.Session() as sess:\n",
    "    model = make_model(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    losses = model.fit(x[:, np.newaxis], targets[:, np.newaxis])\n",
    "    pred = np.squeeze(model.predict(\n",
    "        (x_val[:, np.newaxis] - mean) / (std + 1e-8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping back to (ensemble_size, n_particles, 365days). n_samples will help estimating aleatoric uncertainty and ensemble_size will help estimating epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.reshape(pred, \n",
    "                  (model.ensemble_size, n_particles, time.shape[0]))\n",
    "# For more details on decomposition of uncertainties: http://proceedings.mlr.press/v80/depeweg18a/depeweg18a.pdf \n",
    "aleatoric_uncertainty = np.mean(np.std(pred, axis=1) ** 2, axis=0)\n",
    "epistemic_uncertainty = np.std(np.mean(pred, axis=1), axis=0) ** 2\n",
    "print(aleatoric_uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = fig.subplots()\n",
    "ax.set_ylim([-100, 15e3])\n",
    "ax.scatter(inputs, targets, color='#FF764D', alpha=0.6,\n",
    "           s=5, label='Infectious people a day')\n",
    "# mean = np.mean(pred, axis=(0, 1))\n",
    "mean = pred[0, 0, :]\n",
    "ax.plot(time, mean, '-', color='#C20093', linewidth=1, label='Predictions')\n",
    "ax.fill_between(time, mean - np.sqrt(epistemic_uncertainty), mean + np.sqrt(epistemic_uncertainty),\n",
    "                color='#FC206C', alpha=0.15, label='Epistemic uncertainty')\n",
    "ax.errorbar(time, mean, yerr=np.sqrt(aleatoric_uncertainty), linewidth=0.0,\n",
    "             ecolor='silver', elinewidth=3, capsize=0.0, label='Aleatoric uncertainty')\n",
    "legend = ax.legend(loc='upper right', fontsize='medium')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Infectious people\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# ax = fig.subplots()\n",
    "# ax.set_ylim([-100, 15e3])\n",
    "# ax.scatter(inputs, targets, color='#FF764D', alpha=0.6,\n",
    "#            s=5, label='Infectious people a day')\n",
    "# ax.plot(time, mus, '-', color='#C20093', linewidth=1, label='Predictions')\n",
    "# ax.errorbar(time, mus, yerr=sigmas, linewidth=0.0,\n",
    "#              ecolor='silver', elinewidth=3, capsize=0.0, label='Aleatoric uncertainty', alpha=0.2)\n",
    "# legend = ax.legend(loc='upper right', fontsize='medium')\n",
    "# plt.xlabel(\"Days\")\n",
    "# plt.ylabel(\"Infectious people\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
